è·³è‡³å†…å®¹
å†å²èŠå¤©è®°å½•

æ‚¨è¯´ï¼š
import streamlit as st
import torch
import torch.nn as nn
from torchvision import transforms
import cv2
import numpy as np
from PIL import Image
import os
import requests

from model import YourModel  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹ç±»å
from utils import generate_gradcam  # ä½ è‡ªå·±çš„ Grad-CAM å‡½æ•°

# æ¨¡å‹è·¯å¾„ï¼ˆHugging Face æ¨¡å‹ç›´é“¾ï¼‰
MODEL_URL = "https://huggingface.co/qxliu/srss_model/blob/main/model_final_cb2.pth"
MODEL_PATH = "model_final_cb2.pth"

@st.cache_resource
def load_model():
    if not os.path.exists(MODEL_PATH):
        with st.spinner("â¬ æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶..."):
            r = requests.get(MODEL_URL)
            with open(MODEL_PATH, "wb") as f:
                f.write(r.content)

    model = YourModel()  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹ç±»æ„é€ 
    model.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"))
    model.eval()
    return model

def preprocess(image: Image.Image):
    # å°†PILå›¾åƒè£å‰ªä¸Šéƒ¨60%
    img = np.array(image)
    h = img.shape[0]
    upper_img = img[:int(h * 0.6), :, :]
    image = Image.fromarray(upper_img)

    transform = transforms.Compose([
        transforms.Resize((224, 224)),  # æ ¹æ®è®­ç»ƒæ—¶ä½¿ç”¨çš„å°ºå¯¸ä¿®æ”¹
        transforms.ToTensor(),
    ])
    return transform(image).unsqueeze(0), upper_img

def main():
    st.title("ğŸ§  åŸºäºäººè„¸å›¾åƒçš„ SRSS ç¡çœ è¯„åˆ†é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("ä¸Šä¼ ä¸€å¼ æ­£è„¸ç…§ç‰‡ï¼Œç³»ç»Ÿå°†é¢„æµ‹ä½ çš„ç¡çœ è´¨é‡è¯„åˆ†ï¼ˆSRSS 0-50ï¼‰å¹¶æ˜¾ç¤ºå…³æ³¨åŒºåŸŸã€‚")

    uploaded_file = st.file_uploader("è¯·ä¸Šä¼ å›¾ç‰‡ï¼ˆjpg/pngï¼‰", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="åŸå§‹å›¾åƒ", use_column_width=True)

        input_tensor, cropped = preprocess(image)

        model = load_model()

        with torch.no_grad():
            output = model(input_tensor)
            srss_score = output.item()

        st.subheader(f"ğŸ“Š é¢„æµ‹ SRSS ç¡çœ è¯„åˆ†ï¼š**{srss_score:.2f}**")

        # Grad-CAM å¯è§†åŒ–
        st.subheader("ğŸ¯ æ¨¡å‹å…³æ³¨åŒºåŸŸï¼ˆGrad-CAMï¼‰")
        gradcam_img = generate_gradcam(model, input_tensor, cropped)
        st.image(gradcam_img, caption="Grad-CAM çƒ­åŠ›å›¾", use_column_width=True)

if __name__ == "__main__":
    main()æ ¹æ®è¿™ä¸ªä¿®æ”¹appã€‚pyï¼Œæ‰¿è¢­ä¸Šä¸ªå¯¹è¯æ¡†è®°å¿†
ChatGPT è¯´ï¼š
ä½ æƒ³è¦åŸºäºä¸Šä¸€ä¸ªç‰ˆæœ¬çš„ app.pyï¼Œåœ¨ä¿ç•™ä¸»æµç¨‹çš„å‰æä¸‹ï¼ŒæŠŠ Grad-CAM å’Œæ¨¡å‹ç»“æ„æŒ‰å®é™…é¡¹ç›®ï¼ˆå¸¦ CBAM æ¨¡å—çš„ ResNet18ï¼‰æ•´åˆè¿›æ¥ã€‚æˆ‘ä¼šï¼š

ä½¿ç”¨ä½ å·²æœ‰çš„ YourModel ç±»åŠ è½½æ¨¡å‹ï¼ˆå¦‚ä¸º ResNet18_CBAMï¼‰ã€‚

ä¿ç•™ Grad-CAMï¼Œæ ¹æ®ä½ é¡¹ç›®ä¸­å·²ç»å®ç°çš„ generate_gradcam() å‡½æ•°è°ƒç”¨ã€‚

æ·»åŠ é”™è¯¯å¤„ç†ä¸å¢å¼ºéƒ¨ç½²ç¨³å®šæ€§ï¼ˆé˜²æ­¢ Hugging Face URL æŠ¥é”™ï¼‰ã€‚

åŠ å…¥å¯¹ torch.hub.load_state_dict_from_url() çš„æ›¿ä»£ï¼ˆå› ä½ ä½¿ç”¨ Hugging Face raw blob é“¾æ¥ï¼‰ã€‚

è¿™æ˜¯æ”¹å†™åçš„ app.pyï¼š

import streamlit as st
import torch
import torch.nn as nn
from torchvision import transforms
import cv2
import numpy as np
from PIL import Image
import os
import requests

from model import YourModel  # ä½¿ç”¨ä½ è‡ªå·±çš„æ¨¡å‹ç±»ï¼Œå¦‚ ResNet18_CBAM
from utils import generate_gradcam  # ä½ è‡ªå®šä¹‰çš„ Grad-CAM å¯è§†åŒ–å‡½æ•°

# Hugging Face æ¨¡å‹ç›´é“¾ï¼ˆéœ€ç¡®ä¿ä¸º raw é“¾æ¥ï¼Œå¦åˆ™ requests è·å–çš„æ˜¯HTMLé¡µé¢ï¼‰
MODEL_URL = "https://huggingface.co/qxliu/srss_model/resolve/main/model_final_cb2.pth"
MODEL_PATH = "model_final_cb2.pth"

@st.cache_resource
def load_model():
    # ä¸‹è½½æ¨¡å‹ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
    if not os.path.exists(MODEL_PATH):
        with st.spinner("â¬ æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶..."):
            r = requests.get(MODEL_URL)
            if r.status_code != 200:
                st.error("âŒ æ¨¡å‹æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æˆ–ç¨åå†è¯•ã€‚")
                st.stop()
            with open(MODEL_PATH, "wb") as f:
                f.write(r.content)

    # åˆå§‹åŒ–æ¨¡å‹å¹¶åŠ è½½æƒé‡
    model = YourModel()  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹æ„é€ å‡½æ•°
    state_dict = torch.load(MODEL_PATH, map_location=torch.device("cpu"))
    model.load_state_dict(state_dict)
    model.eval()
    return model

def preprocess(image: Image.Image):
    # è£å‰ªäººè„¸ä¸Šéƒ¨åŒºåŸŸ
    img = np.array(image)
    h = img.shape[0]
    upper_img = img[:int(h * 0.6), :, :]
    image = Image.fromarray(upper_img)

    transform = transforms.Compose([
        transforms.Resize((224, 224)),  # ç¡®ä¿ä¸è®­ç»ƒæ—¶è¾“å…¥ä¸€è‡´
        transforms.ToTensor(),
    ])
    return transform(image).unsqueeze(0), upper_img

def main():
    st.set_page_config(page_title="SRSS ç¡çœ è¯„åˆ†é¢„æµ‹", layout="centered")
    st.title("ğŸ§  åŸºäºäººè„¸å›¾åƒçš„ SRSS ç¡çœ è¯„åˆ†é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("ä¸Šä¼ ä¸€å¼ æ­£è„¸ç…§ç‰‡ï¼Œç³»ç»Ÿå°†é¢„æµ‹ä½ çš„ç¡çœ è´¨é‡è¯„åˆ†ï¼ˆSRSS 0-50ï¼‰å¹¶æ˜¾ç¤ºæ¨¡å‹å…³æ³¨åŒºåŸŸã€‚")

    uploaded_file = st.file_uploader("ğŸ“¤ è¯·ä¸Šä¼ å›¾ç‰‡ï¼ˆjpg/pngï¼‰", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="åŸå§‹å›¾åƒ", use_column_width=True)

        input_tensor, cropped = preprocess(image)

        model = load_model()

        with torch.no_grad():
            output = model(input_tensor)
            srss_score = output.item()

        st.subheader(f"ğŸ“Š é¢„æµ‹ SRSS ç¡çœ è¯„åˆ†ï¼š**{srss_score:.2f}**")

        # Grad-CAM å¯è§†åŒ–
        st.subheader("ğŸ¯ æ¨¡å‹å…³æ³¨åŒºåŸŸï¼ˆGrad-CAMï¼‰")
        gradcam_img = generate_gradcam(model, input_tensor, cropped)
        st.image(gradcam_img, caption="Grad-CAM çƒ­åŠ›å›¾", use_column_width=True)

if __name__ == "__main__":
    main()
âš ï¸ è¯·ç¡®ä¿ä»¥ä¸‹å‡ ç‚¹æ— è¯¯ï¼š
YourModel() å®šä¹‰äº model.pyï¼Œä¸”ä¸ model_final_cb2.pth æƒé‡å…¼å®¹ï¼›

generate_gradcam() å‡½æ•°å¯æ¥å— (model, input_tensor, original_img)ï¼Œè¿”å› np.ndarray æˆ– PIL.Imageï¼›

MODEL_URL æ˜¯ Hugging Face ä¸Šçš„ raw æ–‡ä»¶é“¾æ¥ï¼ˆä¸æ˜¯ blobï¼‰ã€‚

å¦‚æœä½ éœ€è¦æˆ‘ä¸€å¹¶è¡¥ä¸Š generate_gradcam() ç»“æ„ï¼ˆå¦‚é€‚é… CBAM æ³¨æ„åŠ›æ¨¡å‹çš„ hook è®¾ç½®ï¼‰ï¼Œå¯ä»¥å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šä¸€èµ·åŠ ä¸Šã€‚

æ‚¨è¯´ï¼š
æ”¹æˆä¸ä¾èµ–gradcamçš„ï¼huggingfaceç”¨ä¸äº†ï¼ï¼ï¼ï¼ï¼ï¼
ChatGPT è¯´ï¼š
æ˜ç™½äº†ï¼ä½ æƒ³è¦çš„æ˜¯ä¸€ä¸ªä¸ä¾èµ– Grad-CAMï¼Œä¹Ÿä¸ä½¿ç”¨ Hugging Face æ¨¡å‹åœ¨çº¿ä¸‹è½½çš„ç‰ˆæœ¬ï¼Œç›´æ¥ç”¨æœ¬åœ°æ¨¡å‹æƒé‡ï¼Œç®€å•åŠ è½½ï¼Œåšæ¨æ–­ï¼Œå±•ç¤ºé¢„æµ‹ç»“æœå’Œè£å‰ªå›¾åƒå°±è¡Œã€‚

æˆ‘å¸®ä½ æ”¹æˆï¼š

å»æ‰æ‰€æœ‰ Grad-CAM ç›¸å…³ä»£ç 

å»æ‰ Hugging Face ä¸‹è½½ï¼Œç›´æ¥æœ¬åœ°åŠ è½½æ¨¡å‹æ–‡ä»¶ï¼ˆæ¨¡å‹æ–‡ä»¶éœ€æ‰‹åŠ¨æ”¾åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼‰

åªä¿ç•™ä¸Šä¼ å›¾ç‰‡ï¼Œè£å‰ªä¸Šéƒ¨ï¼Œé¢„æµ‹ï¼Œæ˜¾ç¤ºåŸå›¾å’Œè£å‰ªå›¾ï¼Œå¹¶è¾“å‡ºé¢„æµ‹åˆ†æ•°

è¿™æ˜¯ä¿®æ”¹åçš„ app.py ä»£ç ï¼š

import streamlit as st
import torch
from torchvision import transforms
import numpy as np
from PIL import Image
import os

from model import YourModel  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹ç±»å

MODEL_PATH = "model_final_cb2.pth"  # è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²æ”¾åˆ°æœ¬åœ°æ­¤è·¯å¾„

@st.cache_resource
def load_model():
    if not os.path.exists(MODEL_PATH):
        st.error(f"æ¨¡å‹æ–‡ä»¶ {MODEL_PATH} ä¸å­˜åœ¨ï¼Œè¯·å…ˆæŠŠæ¨¡å‹æ–‡ä»¶æ”¾åˆ°è¯¥è·¯å¾„ã€‚")
        st.stop()
    model = YourModel()  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹æ„é€ å‡½æ•°
    state_dict = torch.load(MODEL_PATH, map_location="cpu")
    model.load_state_dict(state_dict)
    model.eval()
    return model

def preprocess(image: Image.Image):
    img = np.array(image)
    h = img.shape[0]
    upper_img = img[:int(h * 0.6), :, :]
    image = Image.fromarray(upper_img)

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])
    return transform(image).unsqueeze(0), upper_img

def main():
    st.title("ğŸ§  åŸºäºäººè„¸å›¾åƒçš„ SRSS ç¡çœ è¯„åˆ†é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("ä¸Šä¼ ä¸€å¼ æ­£è„¸ç…§ç‰‡ï¼Œç³»ç»Ÿå°†é¢„æµ‹ä½ çš„ç¡çœ è´¨é‡è¯„åˆ†ï¼ˆSRSS 0-50ï¼‰ã€‚")

    uploaded_file = st.file_uploader("è¯·ä¸Šä¼ å›¾ç‰‡ï¼ˆjpg/pngï¼‰", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="åŸå§‹å›¾åƒ", use_column_width=True)

        input_tensor, cropped = preprocess(image)

        model = load_model()

        with torch.no_grad():
            output = model(input_tensor)
            srss_score = output.item()

        st.subheader(f"ğŸ“Š é¢„æµ‹ SRSS ç¡çœ è¯„åˆ†ï¼š**{srss_score:.2f}**")

        st.image(cropped, caption="è£å‰ªåçš„ä¸Šéƒ¨é¢éƒ¨åŒºåŸŸ", use_column_width=True)

if __name__ == "__main__":
    main()
ä½¿ç”¨è¯´æ˜ï¼š
è¯·æŠŠä½ çš„æ¨¡å‹æƒé‡æ–‡ä»¶ model_final_cb2.pth æ”¾åˆ°å’Œ app.py åŒç›®å½•ä¸‹

YourModel æ›¿æ¢æˆä½ é¡¹ç›®é‡Œå®é™…æ¨¡å‹ç±»åå’Œæ„é€ æ–¹å¼

ä¸Šä¼ äººè„¸å›¾ç‰‡åï¼Œé¡µé¢æ˜¾ç¤ºåŸå›¾ã€è£å‰ªçš„è„¸éƒ¨ä¸Šéƒ¨ã€é¢„æµ‹åˆ†æ•°

éœ€è¦æˆ‘å¸®ä½ å†™ä¸€ä¸ªç®€å•ç¤ºä¾‹çš„ YourModel ä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï¼æˆ–è€…éœ€è¦å¸®ä½ æ”¹æˆåŠ è½½ .pt æ ¼å¼æ¨¡å‹æƒé‡ä¹Ÿæ²¡é—®é¢˜ã€‚

æ‚¨è¯´ï¼š
ä¸å¯¹ï¼Œæˆ‘æ˜¯è®©ä½ æ”¹ä¸€ä¸ªä¸ä¾èµ–gradcamçš„ï¼Œæ²¡è®©ä½ æŠŠhuggingfaceä¸‹è½½ä¹Ÿå»æ‰
ChatGPT è¯´ï¼š
æ˜ç™½äº†ï¼Œä½ æƒ³ä¿ç•™æ¨¡å‹ä» Hugging Face ä¸‹è½½çš„åŠŸèƒ½ï¼ˆè‡ªåŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼‰ï¼Œä½†æ˜¯ä¸ä½¿ç”¨ Grad-CAM ç›¸å…³ä»£ç ï¼Œå³åªåšé¢„æµ‹å’Œæ˜¾ç¤ºåŸå›¾ã€è£å‰ªå›¾ä»¥åŠé¢„æµ‹åˆ†æ•°ã€‚

æˆ‘ç»™ä½ æ”¹æˆå¦‚ä¸‹ç‰ˆæœ¬ï¼š

ä¿ç•™ä» Hugging Face ä¸‹è½½æ¨¡å‹æ–‡ä»¶çš„é€»è¾‘ï¼ˆç”¨ requests ä¸‹è½½ raw æ–‡ä»¶ï¼‰

å»æ‰æ‰€æœ‰å’Œ Grad-CAM ç›¸å…³çš„éƒ¨åˆ†ï¼ˆåŒ…æ‹¬è°ƒç”¨ã€æ˜¾ç¤ºç­‰ï¼‰

ä¿ç•™ä¸Šä¼ å›¾ç‰‡ã€è£å‰ªä¸Šéƒ¨ã€æ¨¡å‹æ¨æ–­ã€å±•ç¤ºç»“æœåŠŸèƒ½

import streamlit as st
import torch
from torchvision import transforms
import numpy as np
from PIL import Image
import os
import requests

from model import YourModel  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹ç±»å

# Hugging Face æ¨¡å‹ raw æ–‡ä»¶é“¾æ¥ï¼Œç¡®ä¿é“¾æ¥æŒ‡å‘å®é™…æƒé‡æ–‡ä»¶
MODEL_URL = "https://huggingface.co/qxliu/srss_model/resolve/main/model_final_cb2.pth"
MODEL_PATH = "model_final_cb2.pth"

@st.cache_resource
def load_model():
    if not os.path.exists(MODEL_PATH):
        with st.spinner("â¬ æ­£åœ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶..."):
            r = requests.get(MODEL_URL)
            if r.status_code != 200:
                st.error("âŒ æ¨¡å‹æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æˆ–ç¨åå†è¯•ã€‚")
                st.stop()
            with open(MODEL_PATH, "wb") as f:
                f.write(r.content)

    model = YourModel()  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹æ„é€ å‡½æ•°
    state_dict = torch.load(MODEL_PATH, map_location="cpu")
    model.load_state_dict(state_dict)
    model.eval()
    return model

def preprocess(image: Image.Image):
    img = np.array(image)
    h = img.shape[0]
    upper_img = img[:int(h * 0.6), :, :]
    image = Image.fromarray(upper_img)

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
    ])
    return transform(image).unsqueeze(0), upper_img

def main():
    st.title("ğŸ§  åŸºäºäººè„¸å›¾åƒçš„ SRSS ç¡çœ è¯„åˆ†é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("ä¸Šä¼ ä¸€å¼ æ­£è„¸ç…§ç‰‡ï¼Œç³»ç»Ÿå°†é¢„æµ‹ä½ çš„ç¡çœ è´¨é‡è¯„åˆ†ï¼ˆSRSS 0-50ï¼‰ã€‚")

    uploaded_file = st.file_uploader("è¯·ä¸Šä¼ å›¾ç‰‡ï¼ˆjpg/pngï¼‰", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="åŸå§‹å›¾åƒ", use_column_width=True)

        input_tensor, cropped = preprocess(image)

        model = load_model()

        with torch.no_grad():
            output = model(input_tensor)
            srss_score = output.item()

        st.subheader(f"ğŸ“Š é¢„æµ‹ SRSS ç¡çœ è¯„åˆ†ï¼š**{srss_score:.2f}**")

        st.image(cropped, caption="è£å‰ªåçš„ä¸Šéƒ¨é¢éƒ¨åŒºåŸŸ", use_column_width=True)

if __name__ == "__main__":
    main()

